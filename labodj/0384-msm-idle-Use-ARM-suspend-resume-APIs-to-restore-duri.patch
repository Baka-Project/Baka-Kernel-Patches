From 0a2254823cb9174d54c79c1dbc739696d03643f6 Mon Sep 17 00:00:00 2001
From: Mahesh Sivasubramanian <msivasub@codeaurora.org>
Date: Tue, 15 Oct 2013 14:36:58 -0600
Subject: [PATCH 384/590] msm: idle: Use ARM suspend/resume APIs to restore
 during warmboot

ARM generic cpu_suspend/resume APIs restore the necessary CP15 registers
to a known state when resuming from a reset state. Use of generic
suspend/resume APIs allows the msm warmboot code to not care about
restoring core registers used by ARM kernel. Also, the PM subsystem no
longer needs to allocate page table or uncached memory to save CPU
registers.

While at it convert most of the assembler code into respective C
function except for warmboot code that executes with MMU turned off.
Also, the idle subsystem no longer needs to manage a  page table or
uncached memory to save CPU registers.

Change-Id: I78a75d0a3c703390eec476199c7ca2786360e12a
Signed-off-by: Mahesh Sivasubramanian <msivasub@codeaurora.org>
Signed-off-by: Karthik Parsha <kparsha@codeaurora.org>
Signed-off-by: franciscofranco <franciscofranco.1990@gmail.com>
Signed-off-by: Simarpreet Singh <simar@linux.com>
---
 arch/arm/mach-msm/idle-v7.S       |  325 +------------------------------------
 arch/arm/mach-msm/idle.h          |   29 +---
 arch/arm/mach-msm/lpm_resources.c |    6 -
 arch/arm/mach-msm/pm-8x60.c       |  181 ++++++++++++++-------
 arch/arm/mach-msm/pm.h            |   15 +-
 5 files changed, 137 insertions(+), 419 deletions(-)

diff --git a/arch/arm/mach-msm/idle-v7.S b/arch/arm/mach-msm/idle-v7.S
index 6840f1c..c0542d0 100644
--- a/arch/arm/mach-msm/idle-v7.S
+++ b/arch/arm/mach-msm/idle-v7.S
@@ -19,286 +19,9 @@
 #include <linux/threads.h>
 #include <asm/assembler.h>
 
-#include "idle.h"
 #include "idle-macros.S"
 
-#ifdef CONFIG_MSM_SCM
-#define SCM_SVC_BOOT 0x1
-#define SCM_CMD_TERMINATE_PC 0x2
-#endif
-
-ENTRY(msm_arch_idle)
-#ifdef CONFIG_ARCH_MSM_KRAIT
-	mrc 	p15, 0, r0, c0, c0, 0
-	bic	r1, r0, #0xff
-	movw	r2, #0x0400
-	movt	r2, #0x511F
-	movw	r3, #0x0600
-	movt	r3, #0x510F
-	cmp	r2, r1
-	cmpne	r3, r1
-	bne	go_wfi
-
-	mrs	r0, cpsr
-	cpsid	if
-
-	mrc	p15, 7, r1, c15, c0, 5
-	bic	r2, r1, #0x20000
-	mcr	p15, 7, r2, c15, c0, 5
-	isb
-
-go_wfi:
-	wfi
-	bne	wfi_done
-	mcr	p15, 7, r1, c15, c0, 5
-	isb
-	msr	cpsr_c, r0
-
-wfi_done:
-	bx	lr
-#else
-	wfi
-#ifdef CONFIG_ARCH_MSM8X60
-	mrc	p14, 1, r1, c1, c5, 4 /* read ETM PDSR to clear sticky bit */
-	mrc     p14, 0, r1, c1, c5, 4 /* read DBG PRSR to clear sticky bit */
-	isb
-#endif
-	bx	lr
-#endif
-
-ENTRY(msm_pm_collapse)
-#if defined(CONFIG_MSM_FIQ_SUPPORT)
-	cpsid   f
-#endif
-
-	ldr     r0, =msm_saved_state	/* address of msm_saved_state ptr */
-	ldr	r0, [r0]		/* load ptr */
-#if (NR_CPUS >= 2)
-	mrc	p15, 0, r1, c0, c0, 5	/* MPIDR */
-	ands	r1, r1, #15		/* What CPU am I */
-	mov	r2, #CPU_SAVED_STATE_SIZE
-	mul	r1, r1, r2
-	add	r0, r0, r1
-#endif
-
-	stmia   r0!, {r4-r14}
-	mrc     p15, 0, r1, c1, c0, 0 /* MMU control */
-	mrc     p15, 0, r2, c2, c0, 0 /* TTBR0 */
-	mrc     p15, 0, r3, c3, c0, 0 /* dacr */
-#ifdef CONFIG_ARCH_MSM_SCORPION
-	/* This instruction is not valid for non scorpion processors */
-	mrc     p15, 3, r4, c15, c0, 3 /* L2CR1 is the L2 cache control reg 1 */
-#endif
-	mrc     p15, 0, r5, c10, c2, 0 /* PRRR */
-	mrc     p15, 0, r6, c10, c2, 1 /* NMRR */
-	mrc     p15, 0, r7, c1, c0, 1 /* ACTLR */
-	mrc     p15, 0, r8, c2, c0, 1 /* TTBR1 */
-	mrc     p15, 0, r9, c13, c0, 3 /* TPIDRURO */
-	mrc     p15, 0, ip, c13, c0, 1 /* context ID */
-	stmia   r0!, {r1-r9, ip}
-
-#if defined(CONFIG_MSM_JTAG) || defined(CONFIG_MSM_JTAG_MM)
-	bl      msm_jtag_save_state
-#endif
-
-	ldr	r0, =msm_pm_flush_l2_flag
-	ldr	r0, [r0]
-	mov	r1, #0
-	mcr	p15, 2, r1, c0, c0, 0 /*CCSELR*/
-	isb
-	mrc	p15, 1, r1, c0, c0, 0 /*CCSIDR*/
-	mov	r2, #1
-	and	r1, r2, r1, ASR #30 /* Check if the cache is write back */
-	orr	r1, r0, r1
-	cmp	r1, #1
-	bne	skip
-	bl	v7_flush_dcache_all
-	ldr	r1, =msm_pm_flush_l2_fn
-	ldr	r1, [r1]
-	cmp	r1, #0
-	blxne	r1
-
-skip:
-	ldr	r1, =msm_pm_disable_l2_fn
-	ldr	r1, [r1]
-	cmp	r1, #0
-	blxne	r1
-	dmb
-
-	mrc	p15, 0, r0, c0, c0, 5	/* MPIDR */
-	and	r0, r0, #15		/* what CPU am I */
-
-	ldr	r1, =msm_pc_debug_counters /*load the IMEM debug location */
-	ldr	r1, [r1]
-	cmp	r1, #0
-	beq	skip_pc_debug1
-	add	r1, r1, r0, LSL #4	/* debug location for this CPU */
-	ldr	r2, [r1]
-	add	r2, #1
-	str	r2, [r1]
-skip_pc_debug1:
-
-#ifdef CONFIG_MSM_SCM
-	ldr	r0, =SCM_SVC_BOOT
-	ldr	r1, =SCM_CMD_TERMINATE_PC
-	ldr	r2, =msm_pm_flush_l2_flag
-	ldr	r2, [r2]
-	bl	scm_call_atomic1
-#else
-	mrc     p15, 0, r4, c1, c0, 0    /* read current CR    */
-	bic     r0, r4, #(1 << 2)        /* clear dcache bit   */
-	bic     r0, r0, #(1 << 12)       /* clear icache bit   */
-	mcr     p15, 0, r0, c1, c0, 0    /* disable d/i cache  */
-	isb
-
-	SUSPEND_8x25_L2
-	SET_SMP_COHERENCY OFF
-	wfi
-	DELAY_8x25 300
-
-	mcr     p15, 0, r4, c1, c0, 0    /* restore d/i cache  */
-	isb
-	ENABLE_8x25_L2 /* enable only l2, no need to restore the reg back */
-	SET_SMP_COHERENCY ON
-#endif
-
-#if defined(CONFIG_MSM_FIQ_SUPPORT)
-	cpsie   f
-#endif
-	mrc	p15, 0, r0, c0, c0, 5 /* MPIDR */
-	and	r0, r0, #15              /* what CPU am I                  */
-
-	ldr	r1, =msm_pc_debug_counters /*load the IMEM debug location */
-	ldr	r1, [r1]
-	cmp	r1, #0
-	beq	skip_pc_debug2
-	add	r1, r1, r0, LSL #4	/* debug location for this CPU */
-	add	r1, #8
-	ldr	r2, [r1]
-	add	r2, #1
-	str	r2, [r1]
-
-skip_pc_debug2:
-	ldr	r1, =msm_pm_enable_l2_fn
-	ldr	r1, [r1]
-	cmp	r1, #0
-	blxne	r1
-	dmb
-
-#if defined(CONFIG_MSM_JTAG) || defined(CONFIG_MSM_JTAG_MM)
-	bl	msm_jtag_restore_state
-#endif
-	ldr     r0, =msm_saved_state	/* address of msm_saved_state ptr */
-	ldr	r0, [r0]		/* load ptr */
-#if (NR_CPUS >= 2)
-	mrc	p15, 0, r1, c0, c0, 5	/* MPIDR */
-	ands	r1, r1, #15		/* What CPU am I */
-	mov	r2, #CPU_SAVED_STATE_SIZE
-	mul	r2, r2, r1
-	add	r0, r0, r2
-#endif
-	ldmfd   r0, {r4-r14}		 /* restore registers */
-	mov     r0, #0                   /* return power collapse failed */
-	bx      lr
-
-ENTRY(msm_pm_collapse_exit)
-#if 0 /* serial debug */
-	mov     r0, #0x80000016
-	mcr     p15, 0, r0, c15, c2, 4
-	mov     r0, #0xA9000000
-	add     r0, r0, #0x00A00000 /* UART1 */
-	/*add     r0, r0, #0x00C00000*/ /* UART3 */
-	mov     r1, #'A'
-	str     r1, [r0, #0x00C]
-#endif
-	ldr     r1, =msm_saved_state_phys
-	ldr     r2, =msm_pm_collapse_exit
-	adr     r3, msm_pm_collapse_exit
-	add     r1, r1, r3
-	sub     r1, r1, r2
-	ldr	r1, [r1]
-	add	r1, r1, #CPU_SAVED_STATE_SIZE
-#if (NR_CPUS >= 2)
-	mrc	p15, 0, r2, c0, c0, 5	/* MPIDR */
-	ands	r2, r2, #15		/* What CPU am I */
-	mov	r3, #CPU_SAVED_STATE_SIZE
-	mul	r2, r2, r3
-	add	r1, r1, r2
-#endif
-
-	ldmdb   r1!, {r2-r11}
-	mcr     p15, 0, r4, c3, c0, 0 /* dacr */
-	mcr     p15, 0, r3, c2, c0, 0 /* TTBR0 */
-#ifdef CONFIG_ARCH_MSM_SCORPION
-	/* This instruction is not valid for non scorpion processors */
-	mcr     p15, 3, r5, c15, c0, 3 /* L2CR1 */
-#endif
-	mcr     p15, 0, r6, c10, c2, 0 /* PRRR */
-	mcr     p15, 0, r7, c10, c2, 1 /* NMRR */
-	mcr     p15, 0, r8, c1, c0, 1 /* ACTLR */
-	mcr     p15, 0, r9, c2, c0, 1 /* TTBR1 */
-	mcr     p15, 0, r10, c13, c0, 3 /* TPIDRURO */
-	mcr     p15, 0, r11, c13, c0, 1 /* context ID */
-	isb
-	ldmdb   r1!, {r4-r14}
-	ldr	r0, =msm_pm_pc_pgd
-	ldr	r1, =msm_pm_collapse_exit
-	adr	r3, msm_pm_collapse_exit
-	add	r0, r0, r3
-	sub	r0, r0, r1
-	ldr	r0, [r0]
-	mrc     p15, 0, r1, c2, c0, 0 /* save current TTBR0 */
-	and	r3, r1, #0x7f /* mask to get TTB flags */
-	orr	r0, r0, r3 /* add TTB flags to switch TTBR value */
-	mcr     p15, 0, r0, c2, c0, 0 /* temporary switch TTBR0 */
-	isb
-	mcr     p15, 0, r2, c1, c0, 0   /* MMU control */
-	isb
-msm_pm_mapped_pa:
-	/* Switch to virtual */
-	ldr     r0, =msm_pm_pa_to_va
-	mov     pc, r0
-msm_pm_pa_to_va:
-	mcr     p15, 0, r1, c2, c0, 0 /* restore TTBR0 */
-	isb
-	mcr     p15, 0, r3, c8, c7, 0   /* UTLBIALL */
-	mcr     p15, 0, r3, c7, c5, 6   /* BPIALL */
-	dsb
-	isb
-
-#ifdef CONFIG_ARCH_MSM_KRAIT
-	mrc	p15, 0, r1, c0, c0, 0
-	ldr	r3, =0xff00fc00
-	and	r3, r1, r3
-	ldr 	r1, =0x51000400
-	cmp	r3, r1
-	mrceq	p15, 7, r3, c15, c0, 2
-	biceq	r3, r3, #0x400
-	mcreq	p15, 7, r3, c15, c0, 2
-#else
-	RESUME_8x25_L2
-	SET_SMP_COHERENCY ON
-#endif
-
-	ldr	r1, =msm_pm_enable_l2_fn
-	ldr	r1, [r1]
-	cmp	r1, #0
-	stmfd   sp!, {lr}
-	blxne	r1
-	dmb
-#if defined(CONFIG_MSM_JTAG) || defined(CONFIG_MSM_JTAG_MM)
-	bl      msm_jtag_restore_state
-#endif
-	ldmfd   sp!, {lr}
-	mov     r0, #1
-	bx      lr
-	nop
-	nop
-	nop
-	nop
-	nop
-1:	b       1b
-
+	.arm
 ENTRY(msm_pm_boot_entry)
 	mrc     p15, 0, r0, c0, c0, 5    /* MPIDR                          */
 	and     r0, r0, #15              /* what CPU am I                  */
@@ -328,30 +51,10 @@ skip_pc_debug3:
 	add     r1, r1, r0, LSL #2       /* locate boot vector for our cpu */
 	ldr     pc, [r1]                 /* jump                           */
 
-ENTRY(msm_pm_set_l2_flush_flag)
-	ldr     r1, =msm_pm_flush_l2_flag
-	str     r0, [r1]
-	bx      lr
-
-ENTRY(msm_pm_get_l2_flush_flag)
-	ldr     r1, =msm_pm_flush_l2_flag
-	ldr     r0, [r1]
-	bx      lr
+3:	.long	.
 
 	.data
 
-	.globl msm_pm_pc_pgd
-msm_pm_pc_pgd:
-	.long	0x0
-
-	.globl msm_saved_state
-msm_saved_state:
-	.long	0x0
-
-	.globl msm_saved_state_phys
-msm_saved_state_phys:
-	.long	0x0
-
 	.globl msm_pm_boot_vector
 msm_pm_boot_vector:
 	.space  4 * NR_CPUS
@@ -372,30 +75,6 @@ l2x0_base_addr:
 msm_pc_debug_counters_phys:
 	.long 0x0
 
-	.globl msm_pc_debug_counters
-msm_pc_debug_counters:
-	.long 0x0
-
-	.globl msm_pm_enable_l2_fn
-msm_pm_enable_l2_fn:
-	.long 0x0
-
-	.globl msm_pm_disable_l2_fn
-msm_pm_disable_l2_fn:
-	.long 0x0
-
-	.globl msm_pm_flush_l2_fn
-msm_pm_flush_l2_fn:
-	.long 0x0
-
-/*
- * Default the l2 flush flag to 1 so that caches are flushed during power
- * collapse unless the  L2 driver decides to flush them only during L2
- * Power collapse.
- */
-msm_pm_flush_l2_flag:
-	.long 0x1
-
 /*
  * Save & restore l2x0 registers while system is entering and resuming
  * from Power Collapse.
diff --git a/arch/arm/mach-msm/idle.h b/arch/arm/mach-msm/idle.h
index ead86a1..e8d27d6 100644
--- a/arch/arm/mach-msm/idle.h
+++ b/arch/arm/mach-msm/idle.h
@@ -14,48 +14,21 @@
 #ifndef _ARCH_ARM_MACH_MSM_IDLE_H_
 #define _ARCH_ARM_MACH_MSM_IDLE_H_
 
-/* 11 general purpose registers (r4-r14), 10 cp15 registers */
-#define CPU_SAVED_STATE_SIZE (4 * 11 + 4 * 10)
-
 #define ON	1
 #define OFF	0
 #define TARGET_IS_8625	1
 #define POWER_COLLAPSED 1
 
-#ifndef __ASSEMBLY__
-
-int msm_arch_idle(void);
-int msm_pm_collapse(void);
-void msm_pm_collapse_exit(void);
-extern void *msm_saved_state;
-extern void (*msm_pm_disable_l2_fn)(void);
-extern void (*msm_pm_enable_l2_fn)(void);
-extern void (*msm_pm_flush_l2_fn)(void);
-extern unsigned long msm_saved_state_phys;
-
 #ifdef CONFIG_CPU_V7
-void msm_pm_boot_entry(void);
-void msm_pm_set_l2_flush_flag(unsigned int flag);
-int msm_pm_get_l2_flush_flag(void);
-extern unsigned long msm_pm_pc_pgd;
 extern unsigned long msm_pm_boot_vector[NR_CPUS];
 extern uint32_t target_type;
 extern uint32_t apps_power_collapse;
 extern uint32_t *l2x0_base_addr;
+void msm_pm_boot_entry(void);
 #else
-static inline void msm_pm_set_l2_flush_flag(unsigned int flag)
-{
-	/* empty */
-}
 static inline void msm_pm_boot_entry(void)
 {
 	/* empty */
 }
-static inline void msm_pm_write_boot_vector(unsigned int cpu,
-						unsigned long address)
-{
-	/* empty */
-}
-#endif
 #endif
 #endif
diff --git a/arch/arm/mach-msm/lpm_resources.c b/arch/arm/mach-msm/lpm_resources.c
index 415f245..fa16acc 100644
--- a/arch/arm/mach-msm/lpm_resources.c
+++ b/arch/arm/mach-msm/lpm_resources.c
@@ -119,12 +119,6 @@ enum {
 	MSM_LPM_LOCAL_RS_TYPE = 1,
 };
 
-enum {
-	MSM_SCM_L2_ON = 0,
-	MSM_SCM_L2_OFF = 1,
-	MSM_SCM_L2_GDHS = 3,
-};
-
 struct msm_lpm_resource {
 	struct msm_lpm_rs_data rs_data;
 	uint32_t sleep_value;
diff --git a/arch/arm/mach-msm/pm-8x60.c b/arch/arm/mach-msm/pm-8x60.c
index b740cdf..21bed1b 100644
--- a/arch/arm/mach-msm/pm-8x60.c
+++ b/arch/arm/mach-msm/pm-8x60.c
@@ -42,10 +42,13 @@
 #include <mach/trace_msm_low_power.h>
 #include <mach/msm-krait-l2-accessors.h>
 #include <mach/msm_bus.h>
+#include <mach/jtag.h>
+#include <asm/suspend.h>
 #include <asm/cacheflush.h>
 #include <asm/hardware/gic.h>
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
+#include <asm/barrier.h>
 #include <asm/outercache.h>
 #ifdef CONFIG_VFP
 #include <asm/vfp.h>
@@ -63,15 +66,14 @@
 #include <mach/event_timer.h>
 #include <linux/cpu_pm.h>
 
-#define SCM_L2_RETENTION	(0x2)
 #define SCM_CMD_TERMINATE_PC	(0x2)
+#define SCM_CMD_CORE_HOTPLUGGED (0x10)
 
 #define GET_CPU_OF_ATTR(attr) \
 	(container_of(attr, struct msm_pm_kobj_attribute, ka)->cpu)
 
 #define SCLK_HZ (32768)
 
-#define NUM_OF_COUNTERS 3
 #define MAX_BUF_SIZE  512
 
 static int msm_pm_debug_mask = 1;
@@ -97,6 +99,13 @@ enum {
 	MSM_PM_DEBUG_HOTPLUG = BIT(8),
 };
 
+enum msm_pc_count_offsets {
+	MSM_PC_ENTRY_COUNTER,
+	MSM_PC_EXIT_COUNTER,
+	MSM_PC_FALLTHRU_COUNTER,
+	MSM_PC_NUM_COUNTERS,
+};
+
 enum {
 	MSM_PM_MODE_ATTR_SUSPEND,
 	MSM_PM_MODE_ATTR_IDLE,
@@ -142,6 +151,28 @@ static struct clk *pnoc_clk;
 DEFINE_PER_CPU(struct clk *, cpu_clks);
 static struct clk *l2_clk;
 
+static void (*msm_pm_disable_l2_fn)(void);
+static void (*msm_pm_enable_l2_fn)(void);
+static void (*msm_pm_flush_l2_fn)(void);
+static void __iomem *msm_pc_debug_counters;
+
+/*
+ * Default the l2 flush flag to OFF so the caches are flushed during power
+ * collapse unless the explicitly voted by lpm driver.
+ */
+static enum msm_pm_l2_scm_flag msm_pm_flush_l2_flag = MSM_SCM_L2_OFF;
+
+void msm_pm_set_l2_flush_flag(enum msm_pm_l2_scm_flag flag)
+{
+	msm_pm_flush_l2_flag = flag;
+}
+EXPORT_SYMBOL(msm_pm_set_l2_flush_flag);
+
+static enum msm_pm_l2_scm_flag msm_pm_get_l2_flush_flag(void)
+{
+	return msm_pm_flush_l2_flag;
+}
+
 static int msm_pm_get_pc_mode(struct device_node *node,
 		const char *key, uint32_t *pc_mode_val)
 {
@@ -415,6 +446,19 @@ static void msm_pm_config_hw_before_retention(void)
 	return;
 }
 
+static bool msm_pm_is_L1_writeback(void)
+{
+	u32 sel = 0, cache_id;
+
+	asm volatile ("mcr p15, 2, %[ccselr], c0, c0, 0\n\t"
+		      "isb\n\t"
+		      "mrc p15, 1, %[ccsidr], c0, c0, 0\n\t"
+		      :[ccsidr]"=r" (cache_id)
+		      :[ccselr]"r" (sel)
+		     );
+	return cache_id & BIT(31);
+}
+
 static void msm_pm_save_cpu_reg(void)
 {
 	int i;
@@ -431,7 +475,7 @@ static void msm_pm_save_cpu_reg(void)
 	 * when the core resumes, it is capable of supporting the current QSB
 	 * rate. Then restore the active vdd before switching the acpuclk rate.
 	 */
-	if (msm_pm_get_l2_flush_flag() == 1) {
+	if (msm_pm_get_l2_flush_flag() == MSM_SCM_L2_OFF) {
 		cp15_data.active_vdd = msm_spm_get_vdd(0);
 		for (i = 0; i < cp15_data.reg_saved_state_size; i++)
 			cp15_data.reg_val[i] =
@@ -449,7 +493,7 @@ static void msm_pm_restore_cpu_reg(void)
 	if (smp_processor_id())
 		return;
 
-	if (msm_pm_get_l2_flush_flag() == 1) {
+	if (msm_pm_get_l2_flush_flag() == MSM_SCM_L2_OFF) {
 		for (i = 0; i < cp15_data.reg_saved_state_size; i++)
 			set_l2_indirect_reg(
 					cp15_data.reg_data[i],
@@ -458,6 +502,12 @@ static void msm_pm_restore_cpu_reg(void)
 	}
 }
 
+static inline void msm_arch_idle(void)
+{
+	mb();
+	wfi();
+}
+
 static void msm_pm_swfi(void)
 {
 	msm_pm_config_hw_before_swfi();
@@ -474,19 +524,77 @@ static void msm_pm_retention(void)
 
 	if (msm_pm_retention_calls_tz)
 		scm_call_atomic1(SCM_SVC_BOOT, SCM_CMD_TERMINATE_PC,
-					SCM_L2_RETENTION);
+					MSM_SCM_L2_RET);
 	else
 		msm_arch_idle();
 
 	msm_pm_config_hw_after_retention();
 }
 
+static inline void msm_pc_inc_debug_count(uint32_t cpu,
+		enum msm_pc_count_offsets offset)
+{
+	uint32_t cnt;
+
+	if (!msm_pc_debug_counters)
+		return;
+
+	cnt = readl_relaxed(msm_pc_debug_counters + cpu * 4 + offset * 4);
+	writel_relaxed(++cnt, msm_pc_debug_counters + cpu * 4 + offset * 4);
+	mb();
+}
+
+static bool msm_pm_pc_hotplug(void)
+{
+	uint32_t cpu = smp_processor_id();
+
+	if (msm_pm_is_L1_writeback())
+		flush_cache_louis();
+
+	msm_pc_inc_debug_count(cpu, MSM_PC_ENTRY_COUNTER);
+
+	scm_call_atomic1(SCM_SVC_BOOT, SCM_CMD_TERMINATE_PC,
+			SCM_CMD_CORE_HOTPLUGGED);
+
+	/* Should not return here */
+	msm_pc_inc_debug_count(cpu, MSM_PC_FALLTHRU_COUNTER);
+	return 0;
+}
+
+static int msm_pm_collapse(unsigned long unused)
+{
+	uint32_t cpu = smp_processor_id();
+
+	if (msm_pm_get_l2_flush_flag() == MSM_SCM_L2_OFF) {
+		flush_cache_all();
+		if (msm_pm_flush_l2_fn)
+			msm_pm_flush_l2_fn();
+	} else if (msm_pm_is_L1_writeback())
+		flush_cache_louis();
+
+	if (msm_pm_disable_l2_fn)
+		msm_pm_disable_l2_fn();
+
+	msm_pc_inc_debug_count(cpu, MSM_PC_ENTRY_COUNTER);
+
+	scm_call_atomic1(SCM_SVC_BOOT, SCM_CMD_TERMINATE_PC,
+				msm_pm_get_l2_flush_flag());
+
+	msm_pc_inc_debug_count(cpu, MSM_PC_FALLTHRU_COUNTER);
+
+	if (msm_pm_enable_l2_fn)
+		msm_pm_enable_l2_fn();
+
+	return 0;
+}
+
 static bool __ref msm_pm_spm_power_collapse(
 	unsigned int cpu, bool from_idle, bool notify_rpm)
 {
 	void *entry;
 	bool collapsed = 0;
 	int ret;
+	bool save_cpu_regs = !cpu || from_idle;
 	unsigned int saved_gic_cpu_ctrl;
 
 	saved_gic_cpu_ctrl = readl_relaxed(MSM_QGIC_CPU_BASE + GIC_CPU_CTRL);
@@ -503,8 +611,8 @@ static bool __ref msm_pm_spm_power_collapse(
 			MSM_SPM_MODE_POWER_COLLAPSE, notify_rpm);
 	WARN_ON(ret);
 
-	entry = (!cpu || from_idle) ?
-		msm_pm_collapse_exit : msm_secondary_startup;
+	entry = save_cpu_regs ?  cpu_resume : msm_secondary_startup;
+
 	msm_pm_boot_config_before_pc(cpu, virt_to_phys(entry));
 
 	if (MSM_PM_DEBUG_RESET_VECTOR & msm_pm_debug_mask)
@@ -513,10 +621,10 @@ static bool __ref msm_pm_spm_power_collapse(
 	if (from_idle && msm_pm_pc_reset_timer)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &cpu);
 
-#ifdef CONFIG_VFP
-	vfp_pm_suspend();
-#endif
-	collapsed = msm_pm_collapse();
+	msm_jtag_save_state();
+	collapsed = save_cpu_regs ?
+		!cpu_suspend(0, msm_pm_collapse) : msm_pm_pc_hotplug();
+	msm_jtag_restore_state();
 
 	if (from_idle && msm_pm_pc_reset_timer)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT, &cpu);
@@ -1345,55 +1453,6 @@ static struct platform_driver msm_cpu_pm_snoc_client_driver = {
 	},
 };
 
-
-static int __init msm_pm_setup_saved_state(void)
-{
-	pgd_t *pc_pgd;
-	pmd_t *pmd;
-	unsigned long pmdval;
-	unsigned long exit_phys;
-
-	/* Page table for cores to come back up safely. */
-	pc_pgd = pgd_alloc(&init_mm);
-	if (!pc_pgd)
-		return -ENOMEM;
-
-	exit_phys = virt_to_phys(msm_pm_collapse_exit);
-
-	pmd = pmd_offset(pud_offset(pc_pgd + pgd_index(exit_phys),exit_phys),
-					exit_phys);
-	pmdval = (exit_phys & PGDIR_MASK) |
-		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE;
-	pmd[0] = __pmd(pmdval);
-	pmd[1] = __pmd(pmdval + (1 << (PGDIR_SHIFT - 1)));
-
-	msm_saved_state_phys =
-		allocate_contiguous_ebi_nomap(CPU_SAVED_STATE_SIZE *
-					      num_possible_cpus(), 4);
-	if (!msm_saved_state_phys)
-		return -ENOMEM;
-	msm_saved_state = ioremap_nocache(msm_saved_state_phys,
-					  CPU_SAVED_STATE_SIZE *
-					  num_possible_cpus());
-	if (!msm_saved_state)
-		return -ENOMEM;
-
-	/* It is remotely possible that the code in msm_pm_collapse_exit()
-	 * which turns on the MMU with this mapping is in the
-	 * next even-numbered megabyte beyond the
-	 * start of msm_pm_collapse_exit().
-	 * Map this megabyte in as well.
-	 */
-	pmd[2] = __pmd(pmdval + (2 << (PGDIR_SHIFT - 1)));
-	flush_pmd_entry(pmd);
-	msm_pm_pc_pgd = virt_to_phys(pc_pgd);
-	clean_caches((unsigned long)&msm_pm_pc_pgd, sizeof(msm_pm_pc_pgd),
-		     virt_to_phys(&msm_pm_pc_pgd));
-
-	return 0;
-}
-core_initcall(msm_pm_setup_saved_state);
-
 static void setup_broadcast_timer(void *arg)
 {
 	int cpu = smp_processor_id();
@@ -1484,7 +1543,7 @@ static int msm_pc_debug_counters_copy(
 				sizeof(data->buf)-data->len,
 				"CPU%d\n", cpu);
 
-			for (j = 0; j < NUM_OF_COUNTERS; j++) {
+			for (j = 0; j < MSM_PC_NUM_COUNTERS; j++) {
 				stat = msm_pc_debug_counters_read_register(
 						data->reg, cpu, j);
 				data->len += scnprintf(data->buf + data->len,
diff --git a/arch/arm/mach-msm/pm.h b/arch/arm/mach-msm/pm.h
index 8a043d8..fed74dc 100644
--- a/arch/arm/mach-msm/pm.h
+++ b/arch/arm/mach-msm/pm.h
@@ -56,6 +56,13 @@ enum msm_pm_sleep_mode {
 	MSM_PM_SLEEP_MODE_NOT_SELECTED,
 };
 
+enum msm_pm_l2_scm_flag {
+	MSM_SCM_L2_ON = 0,
+	MSM_SCM_L2_OFF = 1,
+	MSM_SCM_L2_RET = 2,
+	MSM_SCM_L2_GDHS = 3,
+};
+
 #define MSM_PM_MODE(cpu, mode_nr)  ((cpu) * MSM_PM_SLEEP_MODE_NR + (mode_nr))
 
 struct msm_pm_time_params {
@@ -136,10 +143,17 @@ void msm_pm_enable_retention(bool enable);
 void msm_pm_set_rpm_wakeup_irq(unsigned int irq);
 void msm_pm_set_sleep_ops(struct msm_pm_sleep_ops *ops);
 int msm_pm_wait_cpu_shutdown(unsigned int cpu);
+void __init msm_pm_sleep_status_init(void);
+void msm_pm_set_l2_flush_flag(enum msm_pm_l2_scm_flag flag);
 #else
 static inline void msm_pm_set_rpm_wakeup_irq(unsigned int irq) {}
 static inline void msm_pm_set_sleep_ops(struct msm_pm_sleep_ops *ops) {}
 static inline int msm_pm_wait_cpu_shutdown(unsigned int cpu) { return 0; }
+static inline void msm_pm_sleep_status_init(void) {};
+static inline void msm_pm_set_l2_flush_flag(unsigned int flag)
+{
+	/* empty */
+}
 #endif
 #ifdef CONFIG_HOTPLUG_CPU
 int msm_platform_secondary_init(unsigned int cpu);
@@ -172,6 +186,5 @@ static inline void msm_pm_add_stat(enum msm_pm_time_stats_id id, int64_t t) {}
 #endif
 
 void msm_pm_set_cpr_ops(struct msm_pm_cpr_ops *ops);
-extern void *msm_pc_debug_counters;
 extern unsigned long msm_pc_debug_counters_phys;
 #endif  /* __ARCH_ARM_MACH_MSM_PM_H */
-- 
1.7.9.5

