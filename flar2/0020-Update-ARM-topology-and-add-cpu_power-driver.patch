From 57495ab6576f244e9ef6a6b1f5b4139dbcc6a888 Mon Sep 17 00:00:00 2001
From: flar2 <asegaert@gmail.com>
Date: Sat, 9 Nov 2013 08:47:38 -0500
Subject: [PATCH 020/276]  Update ARM topology and add cpu_power driver


Signed-off-by: Simarpreet Singh <simar@linux.com>
---
 arch/arm/Kconfig                     |    2 +
 arch/arm/include/asm/topology.h      |   45 +++++
 arch/arm/kernel/smp.c                |    1 +
 arch/arm/kernel/topology.c           |  345 ++++++++++++++++++++++++++++++++--
 drivers/staging/Kconfig              |    4 +
 drivers/staging/Makefile             |    1 +
 drivers/staging/cpupower/Kconfig     |    5 +
 drivers/staging/cpupower/Makefile    |    4 +
 drivers/staging/cpupower/cpu_power.c |  179 ++++++++++++++++++
 include/linux/power/cpupower.h       |   22 +++
 10 files changed, 588 insertions(+), 20 deletions(-)
 create mode 100644 drivers/staging/cpupower/Kconfig
 create mode 100644 drivers/staging/cpupower/Makefile
 create mode 100644 drivers/staging/cpupower/cpu_power.c
 create mode 100644 include/linux/power/cpupower.h

diff --git a/arch/arm/Kconfig b/arch/arm/Kconfig
index 69b2cd2..2530489 100644
--- a/arch/arm/Kconfig
+++ b/arch/arm/Kconfig
@@ -1609,6 +1609,7 @@ config ARM_CPU_TOPOLOGY
 config SCHED_MC
 	bool "Multi-core scheduler support"
 	depends on ARM_CPU_TOPOLOGY
+	default y
 	help
 	  Multi-core scheduler support improves the CPU scheduler's decision
 	  making when dealing with multi-core CPU chips at a cost of slightly
@@ -1617,6 +1618,7 @@ config SCHED_MC
 config SCHED_SMT
 	bool "SMT scheduler support"
 	depends on ARM_CPU_TOPOLOGY
+	default y
 	help
 	  Improves the CPU scheduler's decision making when dealing with
 	  MultiThreading at a cost of slightly increased overhead in some
diff --git a/arch/arm/include/asm/topology.h b/arch/arm/include/asm/topology.h
index 58b8b84..8aae906 100644
--- a/arch/arm/include/asm/topology.h
+++ b/arch/arm/include/asm/topology.h
@@ -6,6 +6,7 @@
 #include <linux/cpumask.h>
 
 struct cputopo_arm {
+	int id;
 	int thread_id;
 	int core_id;
 	int socket_id;
@@ -27,11 +28,55 @@ void init_cpu_topology(void);
 void store_cpu_topology(unsigned int cpuid);
 const struct cpumask *cpu_coregroup_mask(int cpu);
 
+void set_power_scale(unsigned int cpu, unsigned int power);
+int topology_register_notifier(struct notifier_block *nb);
+int topology_unregister_notifier(struct notifier_block *nb);
+
 #else
 
 static inline void init_cpu_topology(void) { }
 static inline void store_cpu_topology(unsigned int cpuid) { }
 
+static inline void set_power_scale(unsigned int cpu, unsigned int power) { }
+static inline int topology_register_notifier(struct notifier_block *nb)  { }
+static inline int topology_unregister_notifier(struct notifier_block *nb)  { }
+
+#endif
+
+/* Topology notifier event */
+#define TOPOLOGY_POSTCHANGE 0
+
+/* Common values for CPUs */
+#ifndef SD_CPU_INIT
+#define SD_CPU_INIT (struct sched_domain) {				\
+	.min_interval		= 1,					\
+	.max_interval		= 4,					\
+	.busy_factor		= 64,					\
+	.imbalance_pct		= 125,					\
+	.cache_nice_tries	= 1,					\
+	.busy_idx		= 2,					\
+	.idle_idx		= 1,					\
+	.newidle_idx		= 0,					\
+	.wake_idx		= 0,					\
+	.forkexec_idx		= 0,					\
+									\
+	.flags			= 1*SD_LOAD_BALANCE			\
+				| 1*SD_BALANCE_NEWIDLE			\
+				| 1*SD_BALANCE_EXEC			\
+				| 1*SD_BALANCE_FORK			\
+				| 0*SD_BALANCE_WAKE			\
+				| 1*SD_WAKE_AFFINE			\
+				| 0*SD_PREFER_LOCAL			\
+				| 0*SD_SHARE_CPUPOWER			\
+				| 0*SD_SHARE_PKG_RESOURCES		\
+				| 0*SD_SERIALIZE			\
+				| arch_sd_sibling_asym_packing()	\
+				| sd_balance_for_package_power()	\
+				| sd_power_saving_flags()		\
+				,					\
+	.last_balance		= jiffies,				\
+	.balance_interval	= 1,					\
+}
 #endif
 
 #include <asm-generic/topology.h>
diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index cf10056..5242c55 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -32,6 +32,7 @@
 #include <asm/cputype.h>
 #include <asm/exception.h>
 #include <asm/idmap.h>
+
 #include <asm/topology.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
diff --git a/arch/arm/kernel/topology.c b/arch/arm/kernel/topology.c
index 8200dea..ab85d94 100644
--- a/arch/arm/kernel/topology.c
+++ b/arch/arm/kernel/topology.c
@@ -18,10 +18,20 @@
 #include <linux/node.h>
 #include <linux/nodemask.h>
 #include <linux/sched.h>
+#include <linux/cpumask.h>
+#include <linux/cpuset.h>
+#include <linux/notifier.h>
+
+#ifdef CONFIG_DEBUG_FS
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>	/* for copy_from_user */
+#endif
 
 #include <asm/cputype.h>
 #include <asm/topology.h>
 
+#define ARM_FAMILY_MASK 0xFF0FFFF0
+
 #define MPIDR_SMP_BITMASK (0x3 << 30)
 #define MPIDR_SMP_VALUE (0x2 << 30)
 
@@ -43,12 +53,203 @@
 
 struct cputopo_arm cpu_topology[NR_CPUS];
 
+
+/*
+ * cpu power scale management
+ * a per cpu data structure should be better because each cpu is mainly
+ * using its own cpu_power even it's not always true because of
+ * nohz_idle_balance
+ */
+
+static DEFINE_PER_CPU(unsigned int, cpu_scale);
+
+/*
+ * cpu topology mask update management
+ */
+
+static unsigned int prev_sched_mc_power_savings = 0;
+static unsigned int prev_sched_smt_power_savings = 0;
+
+ATOMIC_NOTIFIER_HEAD(topology_update_notifier_list);
+
+/*
+ * Update the cpu power of the scheduler
+ */
+unsigned long arch_scale_freq_power(struct sched_domain *sd, int cpu)
+{
+	return per_cpu(cpu_scale, cpu);
+}
+
+void set_power_scale(unsigned int cpu, unsigned int power)
+{
+	per_cpu(cpu_scale, cpu) = power;
+}
+
+int topology_register_notifier(struct notifier_block *nb)
+{
+
+	return atomic_notifier_chain_register(
+				&topology_update_notifier_list, nb);
+}
+
+int topology_unregister_notifier(struct notifier_block *nb)
+{
+
+	return atomic_notifier_chain_unregister(
+				&topology_update_notifier_list, nb);
+}
+
+/*
+ * sched_domain flag configuration
+ */
+/* TODO add a config flag for this function */
+int arch_sd_sibling_asym_packing(void)
+{
+	if (sched_smt_power_savings || sched_mc_power_savings)
+		return SD_ASYM_PACKING;
+	return 0;
+}
+
+/*
+ * default topology function
+ */
 const struct cpumask *cpu_coregroup_mask(int cpu)
 {
 	return &cpu_topology[cpu].core_sibling;
 }
 
 /*
+ * clear cpu topology masks
+ */
+static void clear_cpu_topology_mask(void)
+{
+	unsigned int cpuid;
+	for_each_possible_cpu(cpuid) {
+		struct cputopo_arm *cpuid_topo = &(cpu_topology[cpuid]);
+		cpumask_clear(&cpuid_topo->core_sibling);
+		cpumask_clear(&cpuid_topo->thread_sibling);
+	}
+	smp_wmb();
+}
+
+/*
+ * default_cpu_topology_mask set the core and thread mask as described in the
+ * ARM ARM
+ */
+static void default_cpu_topology_mask(unsigned int cpuid)
+{
+	struct cputopo_arm *cpuid_topo = &cpu_topology[cpuid];
+	unsigned int cpu;
+
+	for_each_possible_cpu(cpu) {
+		struct cputopo_arm *cpu_topo = &cpu_topology[cpu];
+
+		if (cpuid_topo->socket_id == cpu_topo->socket_id) {
+			cpumask_set_cpu(cpuid, &cpu_topo->core_sibling);
+			if (cpu != cpuid)
+				cpumask_set_cpu(cpu,
+					&cpuid_topo->core_sibling);
+
+			if (cpuid_topo->core_id == cpu_topo->core_id) {
+				cpumask_set_cpu(cpuid,
+					&cpu_topo->thread_sibling);
+				if (cpu != cpuid)
+					cpumask_set_cpu(cpu,
+						&cpuid_topo->thread_sibling);
+			}
+		}
+	}
+	smp_wmb();
+}
+
+static void normal_cpu_topology_mask(void)
+{
+	unsigned int cpuid;
+
+	for_each_possible_cpu(cpuid) {
+		default_cpu_topology_mask(cpuid);
+	}
+	smp_wmb();
+}
+
+/*
+ * For Cortex-A9 MPcore, we emulate a multi-package topology in power mode.
+ * The goal is to gathers tasks on 1 virtual package
+ */
+static void power_cpu_topology_mask_CA9(unsigned int cpuid)
+{
+	struct cputopo_arm *cpuid_topo = &cpu_topology[cpuid];
+	unsigned int cpu;
+
+	for_each_possible_cpu(cpu) {
+		struct cputopo_arm *cpu_topo = &cpu_topology[cpu];
+
+		if ((cpuid_topo->socket_id == cpu_topo->socket_id)
+		&& ((cpuid & 0x1) == (cpu & 0x1))) {
+			cpumask_set_cpu(cpuid, &cpu_topo->core_sibling);
+			if (cpu != cpuid)
+				cpumask_set_cpu(cpu,
+					&cpuid_topo->core_sibling);
+
+			if (cpuid_topo->core_id == cpu_topo->core_id) {
+				cpumask_set_cpu(cpuid,
+					&cpu_topo->thread_sibling);
+				if (cpu != cpuid)
+					cpumask_set_cpu(cpu,
+						&cpuid_topo->thread_sibling);
+			}
+		}
+	}
+	smp_wmb();
+}
+
+static int need_topology_update(void)
+{
+	int update;
+
+	update = ((prev_sched_mc_power_savings ^ sched_mc_power_savings)
+	       || (prev_sched_smt_power_savings ^ sched_smt_power_savings));
+
+	prev_sched_mc_power_savings = sched_mc_power_savings;
+	prev_sched_smt_power_savings = sched_smt_power_savings;
+
+	return update;
+}
+
+#define ARM_CORTEX_A9_FAMILY 0x410FC090
+
+/* update_cpu_topology_policy select a cpu topology policy according to the
+ * available cores.
+ * TODO: The current version assumes that all cores are exactly the same which
+ * might not be true. We need to update it to take into account various
+ * configuration among which system with different kind of core.
+ */
+static int update_cpu_topology_mask(void)
+{
+	unsigned long cpuid;
+
+	if (sched_mc_power_savings == POWERSAVINGS_BALANCE_NONE) {
+		normal_cpu_topology_mask();
+		return 0;
+	}
+
+	for_each_possible_cpu(cpuid) {
+		struct cputopo_arm *cpuid_topo = &(cpu_topology[cpuid]);
+
+		switch (cpuid_topo->id) {
+		case ARM_CORTEX_A9_FAMILY:
+			power_cpu_topology_mask_CA9(cpuid);
+		break;
+		default:
+			default_cpu_topology_mask(cpuid);
+		break;
+		}
+	}
+
+	return 0;
+}
+
+/*
  * store_cpu_topology is called at boot when only one cpu is running
  * and with the mutex cpu_hotplug.lock locked, when several cpus have booted,
  * which prevents simultaneous write access to cpu_topology array
@@ -57,7 +258,6 @@ void store_cpu_topology(unsigned int cpuid)
 {
 	struct cputopo_arm *cpuid_topo = &cpu_topology[cpuid];
 	unsigned int mpidr;
-	unsigned int cpu;
 
 	/* If the cpu topology has been already set, just return */
 	if (cpuid_topo->core_id != -1)
@@ -88,6 +288,9 @@ void store_cpu_topology(unsigned int cpuid)
 			cpuid_topo->socket_id = (mpidr >> MPIDR_LEVEL1_SHIFT)
 				& MPIDR_LEVEL1_MASK;
 		}
+
+		cpuid_topo->id = read_cpuid_id() & ARM_FAMILY_MASK;
+
 	} else {
 		/*
 		 * This is an uniprocessor system
@@ -99,26 +302,12 @@ void store_cpu_topology(unsigned int cpuid)
 		cpuid_topo->socket_id = -1;
 	}
 
-	/* update core and thread sibling masks */
-	for_each_possible_cpu(cpu) {
-		struct cputopo_arm *cpu_topo = &cpu_topology[cpu];
+	/*
+	 * The core and thread sibling masks can also be updated during the
+	 * call of arch_update_cpu_topology
+	 */
+	default_cpu_topology_mask(cpuid);
 
-		if (cpuid_topo->socket_id == cpu_topo->socket_id) {
-			cpumask_set_cpu(cpuid, &cpu_topo->core_sibling);
-			if (cpu != cpuid)
-				cpumask_set_cpu(cpu,
-					&cpuid_topo->core_sibling);
-
-			if (cpuid_topo->core_id == cpu_topo->core_id) {
-				cpumask_set_cpu(cpuid,
-					&cpu_topo->thread_sibling);
-				if (cpu != cpuid)
-					cpumask_set_cpu(cpu,
-						&cpuid_topo->thread_sibling);
-			}
-		}
-	}
-	smp_wmb();
 
 	printk(KERN_INFO "CPU%u: thread %d, cpu %d, socket %d, mpidr %x\n",
 		cpuid, cpu_topology[cpuid].thread_id,
@@ -127,6 +316,28 @@ void store_cpu_topology(unsigned int cpuid)
 }
 
 /*
+ * arch_update_cpu_topology is called by the scheduler before building
+ * a new sched_domain hierarchy.
+ */
+int arch_update_cpu_topology(void)
+{
+	if (!need_topology_update())
+		return 0;
+
+	/* clear core threads mask */
+	clear_cpu_topology_mask();
+
+	/* set topology mask */
+	update_cpu_topology_mask();
+
+	/* notify the topology update */
+	atomic_notifier_call_chain(&topology_update_notifier_list,
+				TOPOLOGY_POSTCHANGE, (void *)sched_mc_power_savings);
+
+	return 1;
+}
+
+/*
  * init_cpu_topology is called at boot when only one cpu is running
  * which prevent simultaneous write access to cpu_topology array
  */
@@ -138,11 +349,105 @@ void init_cpu_topology(void)
 	for_each_possible_cpu(cpu) {
 		struct cputopo_arm *cpu_topo = &(cpu_topology[cpu]);
 
+		cpu_topo->id = -1;
 		cpu_topo->thread_id = -1;
 		cpu_topo->core_id =  -1;
 		cpu_topo->socket_id = -1;
 		cpumask_clear(&cpu_topo->core_sibling);
 		cpumask_clear(&cpu_topo->thread_sibling);
+
+		per_cpu(cpu_scale, cpu) = SCHED_POWER_SCALE;
 	}
 	smp_wmb();
 }
+
+/*
+ * debugfs interface for scaling cpu power
+ */
+
+#ifdef CONFIG_DEBUG_FS
+static struct dentry *topo_debugfs_root;
+
+static ssize_t dbg_write(struct file *file, const char __user *buf,
+						size_t size, loff_t *off)
+{
+	unsigned int *value = file->f_dentry->d_inode->i_private;
+	char cdata[128];
+	unsigned long tmp;
+
+	if (size < (sizeof(cdata)-1)) {
+		if (copy_from_user(cdata, buf, size))
+			return -EFAULT;
+		cdata[size] = 0;
+		if (!strict_strtoul(cdata, 10, &tmp)) {
+			*value = tmp;
+		}
+		return size;
+	}
+	return -EINVAL;
+}
+
+static ssize_t dbg_read(struct file *file, char __user *buf,
+						size_t size, loff_t *off)
+{
+	unsigned int *value = file->f_dentry->d_inode->i_private;
+	char cdata[128];
+	unsigned int len;
+
+	len = sprintf(cdata, "%u\n", *value);
+	return simple_read_from_buffer(buf, size, off, cdata, len);
+}
+
+static const struct file_operations debugfs_fops = {
+	.read = dbg_read,
+	.write = dbg_write,
+};
+
+static struct dentry *topo_debugfs_register(unsigned int cpu,
+						struct dentry *parent)
+{
+	struct dentry *cpu_d, *d;
+	char cpu_name[16];
+
+	sprintf(cpu_name, "cpu%u", cpu);
+
+	cpu_d = debugfs_create_dir(cpu_name, parent);
+	if (!cpu_d)
+		return NULL;
+
+	d = debugfs_create_file("cpu_power", S_IRUGO  | S_IWUGO,
+				cpu_d, &per_cpu(cpu_scale, cpu), &debugfs_fops);
+	if (!d)
+		goto err_out;
+
+	return cpu_d;
+
+err_out:
+	debugfs_remove_recursive(cpu_d);
+	return NULL;
+}
+
+static int __init topo_debugfs_init(void)
+{
+	struct dentry *d;
+	unsigned int cpu;
+
+	d = debugfs_create_dir("cpu_topo", NULL);
+	if (!d)
+		return -ENOMEM;
+	topo_debugfs_root = d;
+
+	for_each_possible_cpu(cpu) {
+		d = topo_debugfs_register(cpu, topo_debugfs_root);
+		if (d == NULL)
+			goto err_out;
+	}
+	return 0;
+
+err_out:
+	debugfs_remove_recursive(topo_debugfs_root);
+	return -ENOMEM;
+}
+
+late_initcall(topo_debugfs_init);
+#endif
diff --git a/drivers/staging/Kconfig b/drivers/staging/Kconfig
index 97d412d..1b274d1 100644
--- a/drivers/staging/Kconfig
+++ b/drivers/staging/Kconfig
@@ -132,4 +132,8 @@ source "drivers/staging/ramster/Kconfig"
 
 source "drivers/staging/ozwpan/Kconfig"
 
+source "drivers/staging/media/Kconfig"
+
+source "drivers/staging/cpupower/Kconfig" 
+
 endif # STAGING
diff --git a/drivers/staging/Makefile b/drivers/staging/Makefile
index ffe7d44..bda702c 100644
--- a/drivers/staging/Makefile
+++ b/drivers/staging/Makefile
@@ -52,6 +52,7 @@ obj-$(CONFIG_TOUCHSCREEN_CLEARPAD_TM1217)	+= cptm1217/
 obj-$(CONFIG_TOUCHSCREEN_SYNAPTICS_I2C_RMI4)	+= ste_rmi4/
 obj-$(CONFIG_INTEL_MEI)		+= mei/
 obj-$(CONFIG_MFD_NVEC)		+= nvec/
+obj-$(CONFIG_CPUPOWER)    +=cpupower/
 obj-$(CONFIG_DRM_OMAP)		+= omapdrm/
 obj-$(CONFIG_ANDROID)		+= android/
 obj-$(CONFIG_PHONE)		+= telephony/
diff --git a/drivers/staging/cpupower/Kconfig b/drivers/staging/cpupower/Kconfig
new file mode 100644
index 0000000..e07dd98
--- /dev/null
+++ b/drivers/staging/cpupower/Kconfig
@@ -0,0 +1,5 @@
+config CPUPOWER
+	tristate "cpupower driver"
+	depends on SCHED_MC && ARM_CPU_TOPOLOGY
+	help
+	  Say Y here if you have dual cortex-A9
diff --git a/drivers/staging/cpupower/Makefile b/drivers/staging/cpupower/Makefile
new file mode 100644
index 0000000..b16bad1
--- /dev/null
+++ b/drivers/staging/cpupower/Makefile
@@ -0,0 +1,4 @@
+#
+# Makefile for ARM cpupower driver
+#
+obj-y += cpu_power.o
diff --git a/drivers/staging/cpupower/cpu_power.c b/drivers/staging/cpupower/cpu_power.c
new file mode 100644
index 0000000..9f971a7
--- /dev/null
+++ b/drivers/staging/cpupower/cpu_power.c
@@ -0,0 +1,179 @@
+/*
+ * arch/arm/kernel/topology.c
+ *
+ * Copyright (C) 2011 Linaro Limited.
+ * Written by: Vincent Guittot
+ *
+ * based on arch/sh/kernel/topology.c
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/cpu.h>
+#include <linux/sched.h>
+#include <linux/notifier.h>
+#include <linux/cpufreq.h>
+#include <linux/power/cpupower.h>
+
+static struct cputopo_power **table_config = NULL;
+
+struct cputopo_scale {
+	int id;
+	int freq;
+	struct cputopo_power *power;
+};
+
+/*
+ * The table will be mostly used by one cpu which will update the
+ * configuration for all cpu on a cpufreq notification
+ * or a sched_mc level change
+ */
+static struct cputopo_scale cpu_power[NR_CPUS];
+
+static void set_cpufreq_scale(unsigned int cpuid, unsigned int freq)
+{
+	unsigned int idx;
+
+	cpu_power[cpuid].freq = freq;
+
+	idx = freq / cpu_power[cpuid].power->step;
+	if (idx >= cpu_power[cpuid].power->max)
+		idx = cpu_power[cpuid].power->max - 1;
+
+	set_power_scale(cpuid, cpu_power[cpuid].power->table[idx]);
+	smp_wmb();
+}
+
+static void update_power_scale(unsigned int cpu, unsigned int idx)
+{
+	cpu_power[cpu].id = idx;
+	cpu_power[cpu].power = table_config[idx];
+
+	set_cpufreq_scale(cpu, cpu_power[cpu].freq);
+}
+
+static int topo_cpufreq_transition(struct notifier_block *nb,
+	unsigned long state, void *data)
+{
+	struct cpufreq_freqs *freqs = data;
+
+	if (state == CPUFREQ_POSTCHANGE || state == CPUFREQ_RESUMECHANGE)
+		set_cpufreq_scale(freqs->cpu, freqs->new);
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block topo_cpufreq_nb = {
+	.notifier_call = topo_cpufreq_transition,
+};
+
+static int topo_cpufreq_init(struct platform_device *pdev)
+{
+	unsigned int cpu;
+
+	/* get cpu_power table */
+	table_config = dev_get_platdata(&pdev->dev);
+
+	/* init core mask */
+	for_each_possible_cpu(cpu) {
+		cpu_power[cpu].freq = 0;
+		update_power_scale(cpu, ARM_DEFAULT_SCALE);
+	}
+
+	/* register cpufreq notification */
+	return cpufreq_register_notifier(&topo_cpufreq_nb,
+			CPUFREQ_TRANSITION_NOTIFIER);
+}
+
+static int topo_cpufreq_exit(struct platform_device *pdev)
+{
+	unsigned int cpu;
+
+	/* unregister cpufreq notification */
+	cpufreq_unregister_notifier(&topo_cpufreq_nb,
+			CPUFREQ_TRANSITION_NOTIFIER);
+
+	/* cleay core mask */
+	for_each_possible_cpu(cpu) {
+		cpu_power[cpu].freq = 0;
+		cpu_power[cpu].power = NULL;
+	}
+
+	/* clear cpu_power table */
+	table_config = NULL;
+
+	return 0;
+}
+
+static int topo_policy_transition(struct notifier_block *nb,
+	unsigned long state, void *data)
+{
+	int cpu, idx, level = (int)data;
+
+	if (level == POWERSAVINGS_BALANCE_NONE)
+		idx = ARM_DEFAULT_SCALE;
+	else
+		idx = ARM_POWER_SCALE;
+
+	for_each_possible_cpu(cpu)
+		update_power_scale(cpu, cpu ? ARM_DEFAULT_SCALE : idx );
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block topo_policy_nb = {
+	.notifier_call = topo_policy_transition,
+};
+
+static int __devinit cpupower_probe(struct platform_device *pdev)
+{
+	topo_cpufreq_init(pdev);
+
+	/* register cpufreq notifer */
+	topology_register_notifier(&topo_policy_nb);
+
+	return 0;
+}
+
+static int __devexit cpupower_remove(struct platform_device *pdev)
+{
+	/* unregister cpufreq notifer */
+	topology_unregister_notifier(&topo_policy_nb);
+
+	topo_cpufreq_exit(pdev);
+
+	return 0;
+}
+
+
+static struct platform_driver cpupower_driver = {
+	.driver = {
+		.owner = THIS_MODULE,
+		.name = "cpupower",
+	},
+	.probe = cpupower_probe,
+	.remove = __devexit_p(cpupower_remove),
+};
+
+static int __init cpupower_init(void)
+{
+	return platform_driver_register(&cpupower_driver);
+}
+
+static void __exit cpupower_exit(void)
+{
+	platform_driver_unregister(&cpupower_driver);
+}
+
+core_initcall(cpupower_init);
+module_exit(cpupower_exit);
+
+MODULE_AUTHOR("vincent Guittot");
+MODULE_DESCRIPTION("update cpu_power according to current cpu load driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:" DRIVER_NAME);
diff --git a/include/linux/power/cpupower.h b/include/linux/power/cpupower.h
new file mode 100644
index 0000000..9bc7039
--- /dev/null
+++ b/include/linux/power/cpupower.h
@@ -0,0 +1,22 @@
+/*
+ * cpupower.h
+ *
+ * Copyright (c) 2011 Vincent Guittot <vincent.guittot@linaro.org>
+ *
+ * This file is released under the GPLv2
+ *
+ */
+
+#ifndef _CPUPOWER_H_
+#define _CPUPOWER_H_
+
+#define ARM_DEFAULT_SCALE 0
+#define ARM_POWER_SCALE 1
+
+struct cputopo_power {
+	int max; /* max idx in the table */
+	unsigned int step; /* frequency step for the table */
+	unsigned int *table; /* table of cpu_power */
+};
+
+#endif
-- 
1.7.9.5

