From 062df924a4ac2afbec3ff9f4a42eb2563f068fe3 Mon Sep 17 00:00:00 2001
From: Rohit Gupta <rohgup@codeaurora.org>
Date: Thu, 7 Nov 2013 14:32:16 -0800
Subject: [PATCH 334/517] cpufreq: interactive: sync freq feature for
 interactive governor

1) Add load info to cpufreq_interactive_cpuinfo
2) If load on any other online cpu exceeds sync_freq_load_threshold,
   do not allow the frequency to drop below sync_freq

Adapted to fit my earlier changes to the governor.

Change-Id: I3617e10f87b85178914a18bcf04ac2a31a4f1ec1
Signed-off-by: Rohit Gupta <rohgup@codeaurora.org>
(cherry picked from commit c26e25944543c61b34b1830938bb6f353a2580ac)
Signed-off-by: franciscofranco <franciscofranco.1990@gmail.com>
Signed-off-by: Simarpreet Singh <simar@linux.com>
---
 drivers/cpufreq/cpufreq_interactive.c |   97 ++++++++++++++++++++++++++++++---
 1 file changed, 88 insertions(+), 9 deletions(-)

diff --git a/drivers/cpufreq/cpufreq_interactive.c b/drivers/cpufreq/cpufreq_interactive.c
index 94a6aad..d12e772 100644
--- a/drivers/cpufreq/cpufreq_interactive.c
+++ b/drivers/cpufreq/cpufreq_interactive.c
@@ -55,6 +55,7 @@ struct cpufreq_interactive_cpuinfo {
 	struct rw_semaphore enable_sem;
 	int governor_enabled;
 	unsigned int max_load_freq_divided;
+	int prev_load;
 };
 
 static DEFINE_PER_CPU(struct cpufreq_interactive_cpuinfo, cpuinfo);
@@ -138,6 +139,13 @@ u32 boosted_time;
 
 #define CPU_SYNC_FREQ 960000
 
+/*
+ * If the max load among the other CPUs is higher than sync_freq_load_threshold
+ * then do not let the frequency to drop below sync_freq
+ */
+static unsigned int sync_freq_load_threshold;
+static unsigned int sync_freq;
+
 static int cpufreq_governor_interactive(struct cpufreq_policy *policy,
 		unsigned int event);
 
@@ -365,6 +373,8 @@ static void cpufreq_interactive_timer(unsigned long data)
 	unsigned long flags;
 	bool boosted;
 	unsigned long mod_min_sample_time;
+	int i, max_load_other_cpu;
+	unsigned int max_freq_other_cpu;
 
 	if (!down_read_trylock(&pcpu->enable_sem))
 		return;
@@ -383,22 +393,43 @@ static void cpufreq_interactive_timer(unsigned long data)
 	do_div(cputime_speedadj, delta_time);
 	loadadjfreq = (unsigned int)cputime_speedadj * 100;
 	cpu_load = loadadjfreq / pcpu->target_freq;
+
+	pcpu->prev_load = cpu_load;
 	boosted = now < boostpulse_endtime;
 
-	new_freq = choose_freq(pcpu, loadadjfreq);
+	max_load_other_cpu = 0;
+	max_freq_other_cpu = 0;
+	for_each_online_cpu(i) {
+		struct cpufreq_interactive_cpuinfo *picpu =
+						&per_cpu(cpuinfo, i);
+		if (i == data)
+			continue;
+		if (max_load_other_cpu < picpu->prev_load)
+			max_load_other_cpu = picpu->prev_load;
+
+		if (picpu->policy->cur > max_freq_other_cpu)
+			max_freq_other_cpu = picpu->policy->cur;
+	}
 
-	if (cpu_load >= go_hispeed_load) 
+	if (cpu_load >= go_hispeed_load)
 	{
-		if (new_freq < hispeed_freq)
-		{
+		if (pcpu->target_freq < hispeed_freq) 
 			new_freq = hispeed_freq;
-			pcpu->hispeed_validate_time = now;		
-		}
-	} 
-	else if (boosted) 
+		else
+			new_freq = choose_freq(pcpu, loadadjfreq);
+	}
+	else if (boosted)
 	{
 		if (new_freq < input_boost_freq)
-			new_freq = input_boost_freq; 
+			new_freq = input_boost_freq;
+	}
+	else 
+	{
+		new_freq = choose_freq(pcpu, loadadjfreq);
+		if (sync_freq && (max_freq_other_cpu > sync_freq) &&
+			(max_load_other_cpu > sync_freq_load_threshold) &&
+				(new_freq < sync_freq))
+			new_freq = sync_freq;
 	}
 
 	if (pcpu->target_freq >= hispeed_freq &&
@@ -1091,6 +1122,52 @@ static ssize_t store_io_is_busy(struct kobject *kobj,
 static struct global_attr io_is_busy_attr = __ATTR(io_is_busy, 0644,
 		show_io_is_busy, store_io_is_busy);
 
+static ssize_t show_sync_freq(struct kobject *kobj,
+			struct attribute *attr, char *buf)
+{
+	return sprintf(buf, "%u\n", sync_freq);
+}
+
+static ssize_t store_sync_freq(struct kobject *kobj,
+			struct attribute *attr, const char *buf, size_t count)
+{
+	int ret;
+	unsigned long val;
+
+	ret = kstrtoul(buf, 0, &val);
+	if (ret < 0)
+		return ret;
+	sync_freq = val;
+	return count;
+}
+
+static struct global_attr sync_freq_attr = __ATTR(sync_freq, 0644,
+		show_sync_freq, store_sync_freq);
+
+static ssize_t show_sync_freq_load_threshold(struct kobject *kobj,
+			struct attribute *attr, char *buf)
+{
+	return sprintf(buf, "%u\n", sync_freq_load_threshold);
+}
+
+static ssize_t store_sync_freq_load_threshold(struct kobject *kobj,
+			struct attribute *attr, const char *buf, size_t count)
+{
+	int ret;
+	unsigned long val;
+
+	ret = kstrtoul(buf, 0, &val);
+	if (ret < 0)
+		return ret;
+	sync_freq_load_threshold = val;
+	return count;
+}
+
+static struct global_attr sync_freq_load_threshold_attr =
+		__ATTR(sync_freq_load_threshold, 0644,
+		show_sync_freq_load_threshold, store_sync_freq_load_threshold);
+
+
 static struct attribute *interactive_attributes[] = {
 	&target_loads_attr.attr,
 	&above_hispeed_delay_attr.attr,
@@ -1104,6 +1181,8 @@ static struct attribute *interactive_attributes[] = {
 	&boostpulse_duration.attr,
 	&io_is_busy_attr.attr,
 	&sampling_down_factor_attr.attr,
+	&sync_freq_attr.attr,
+	&sync_freq_load_threshold_attr.attr,
 	NULL,
 };
 
-- 
1.7.9.5

